---
phase: 02-core-domain
plan: 01
type: execute
---

<objective>
Build pure Python domain models for the EA stress test system.

Purpose: Create clean, type-hinted domain models that encapsulate parameters, metrics, and workflow state - providing the foundation for all subsequent phases.
Output: `ea_stress/core/` package with params.py, metrics.py, and state.py modules.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Phase 1 Specifications (contracts to implement)
@.planning/phases/01-specification/specs/step-03-extract-params.md
@.planning/phases/01-specification/specs/step-04-analyze-params.md
@.planning/phases/01-specification/specs/step-05-validate-trades.md
@.planning/phases/01-specification/specs/step-09-backtest-passes.md
@.planning/phases/01-specification/specs/step-10-monte-carlo.md
@.planning/phases/01-specification/specs/optimization-loop-python.md

# Existing code patterns (reference only - do NOT modify)
@engine/state.py
@engine/gates.py
@modules/params.py

# Codebase context
@.planning/codebase/CONVENTIONS.md
@.planning/codebase/ARCHITECTURE.md

**Key Decisions from Phase 1:**
- New package `ea_stress/` alongside existing code
- Old code is read-only until Phase 8
- Use dataclasses for all domain models
- Follow existing conventions (snake_case, 4-space indent, type hints)

**Contracts from specifications:**
- Parameter: name, type, base_type, default, comment, line, optimizable
- OptimizationRange: name, start, stop, step, optimize, fixed_value, skip_reason
- TradeMetrics: profit, profit_factor, max_drawdown_pct, total_trades, win_rate, sharpe_ratio, etc.
- GateResult: name, passed, value, threshold, operator, message
- CompositeScore: Go Live Score with weights (consistency, profit, trades, PF, drawdown)
- WorkflowState: workflow_id, status, steps, metrics, gates, errors
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create params.py - Parameter domain models</name>
  <files>ea_stress/__init__.py, ea_stress/core/__init__.py, ea_stress/core/params.py</files>
  <action>
Create the ea_stress package structure and params.py module with:

1. **Parameter dataclass** (from step-03-extract-params.md):
   - name: str (parameter name)
   - type: str (MQL5 type as written)
   - base_type: str (normalized: int, double, bool, string, enum, datetime, color)
   - default: Optional[str] (default value as string)
   - comment: Optional[str] (inline comment)
   - line: int (line number in source, 1-indexed)
   - optimizable: bool (True for input + numeric types)

2. **OptimizationRange dataclass** (from step-04-analyze-params.md):
   - name: str (parameter name)
   - start: Union[int, float, bool] (range start)
   - stop: Union[int, float, bool] (range end)
   - step: Union[int, float, None] (step size, None for bool)
   - optimize: bool (True = include in optimization)
   - fixed_value: Optional[Any] (if optimize=False, use this)
   - skip_reason: Optional[str] (why skipped)
   - category: Optional[str] (risk, strategy, filter, etc.)
   - rationale: Optional[str] (explanation of range choice)

3. **Validation functions**:
   - validate_range(r: OptimizationRange) -> list[str]: Returns list of error messages (empty = valid)
   - is_valid_base_type(t: str) -> bool: Checks against allowed base types
   - MQL5_BASE_TYPES: frozenset of valid base types

Use @dataclass(frozen=True) for immutability where appropriate. Include __post_init__ validation for OptimizationRange (start <= stop for numeric, step > 0 when optimizing).

Do NOT copy the extraction logic from modules/params.py - only the data structures.
  </action>
  <verify>python -c "from ea_stress.core.params import Parameter, OptimizationRange, validate_range; print('OK')"</verify>
  <done>Parameter and OptimizationRange dataclasses importable, validate_range returns empty list for valid range</done>
</task>

<task type="auto">
  <name>Task 2: Create metrics.py - Trade metrics and scoring models</name>
  <files>ea_stress/core/metrics.py</files>
  <action>
Create metrics.py module with:

1. **TradeMetrics dataclass** (from step-09-backtest-passes.md):
   - profit: float (net profit)
   - profit_factor: float (gross profit / gross loss)
   - max_drawdown_pct: float (equity drawdown %)
   - total_trades: int (trade count)
   - win_rate: float (winning trades %)
   - sharpe_ratio: float (risk-adjusted return)
   - sortino_ratio: float (downside risk-adjusted)
   - expected_payoff: float (average profit per trade)
   - recovery_factor: float (profit / max drawdown)
   - gross_profit: float = 0.0
   - gross_loss: float = 0.0

2. **GateResult dataclass** (from engine/gates.py pattern):
   - name: str (gate identifier)
   - passed: bool (gate pass/fail)
   - value: float (actual measured value)
   - threshold: float (gate threshold)
   - operator: str (>=, <=, ==, >, <)
   - message: Optional[str] (human-readable result)
   - Add to_dict() method for serialization

3. **MonteCarloResult dataclass** (from step-10-monte-carlo.md):
   - iterations: int
   - confidence: float (0-100%, profitable sequences)
   - ruin_probability: float (0-100%, hit 50% drawdown)
   - expected_profit: float (mean)
   - median_profit: float
   - worst_case: float (5th percentile)
   - best_case: float (95th percentile)
   - max_drawdown_median: float
   - max_drawdown_worst: float

4. **CompositeScore calculation** (from step-09-backtest-passes.md):
   - GO_LIVE_SCORE_WEIGHTS: dict with weights (consistency=0.25, total_profit=0.25, trade_count=0.20, profit_factor=0.15, max_drawdown=0.15)
   - GO_LIVE_SCORE_RANGES: dict with normalization ranges
   - calculate_composite_score(metrics: TradeMetrics, forward_result: float = 0, back_result: float = 0) -> float: Returns 0-10 score
   - Consistency logic: both forward+back positive = full score, one positive = 25%, both negative = 0

Include a helper normalize_value(value, min_val, max_val, invert=False) -> float for 0-1 scaling.
  </action>
  <verify>python -c "from ea_stress.core.metrics import TradeMetrics, GateResult, calculate_composite_score; print('OK')"</verify>
  <done>TradeMetrics, GateResult, MonteCarloResult dataclasses importable, calculate_composite_score returns 0-10 float</done>
</task>

<task type="auto">
  <name>Task 3: Create state.py - Workflow state model</name>
  <files>ea_stress/core/state.py</files>
  <action>
Create state.py module with:

1. **WorkflowStatus enum**:
   - PENDING = "pending"
   - IN_PROGRESS = "in_progress"
   - AWAITING_PARAM_ANALYSIS = "awaiting_param_analysis"
   - AWAITING_STATS_ANALYSIS = "awaiting_stats_analysis"
   - AWAITING_EA_FIX = "awaiting_ea_fix"
   - COMPLETED = "completed"
   - FAILED = "failed"

2. **StepResult dataclass**:
   - step_name: str (e.g., "1_load_ea", "3_extract_params")
   - passed: bool
   - result: Optional[dict] (step-specific results)
   - timestamp: Optional[str] (ISO format)
   - error: Optional[str] (error message if failed)

3. **WORKFLOW_STEPS constant** (from engine/state.py):
   - Tuple of all 17 step names in order
   - '1_load_ea', '1b_inject_ontester', '1c_inject_safety', '2_compile', '3_extract_params', '4_analyze_params', '5_validate_trades', '6_create_ini', '7_run_optimization', '8_parse_results', '8b_stats_analysis', '9_backtest_robust', '10_monte_carlo', '11_generate_reports', '12_stress_scenarios', '13_forward_windows', '14_multi_pair'

4. **WorkflowState dataclass**:
   - workflow_id: str
   - ea_name: str
   - ea_path: str
   - terminal: str
   - symbol: str = "EURUSD"
   - timeframe: str = "H1"
   - status: WorkflowStatus = WorkflowStatus.PENDING
   - current_step: Optional[str] = None
   - steps: dict[str, StepResult] = field(default_factory=dict)
   - metrics: dict[str, float] = field(default_factory=dict)
   - gates: dict[str, dict] = field(default_factory=dict)
   - errors: list[str] = field(default_factory=list)
   - created_at: Optional[str] = None
   - updated_at: Optional[str] = None

5. **State methods** (as standalone functions for immutability):
   - get_step_result(state: WorkflowState, step_name: str) -> Optional[StepResult]
   - is_step_complete(state: WorkflowState, step_name: str) -> bool
   - get_next_step(state: WorkflowState) -> Optional[str]
   - to_dict(state: WorkflowState) -> dict (for JSON serialization)
   - from_dict(data: dict) -> WorkflowState (for deserialization)

Use enum.Enum for WorkflowStatus. Do NOT implement persistence (that's Phase 6).
  </action>
  <verify>python -c "from ea_stress.core.state import WorkflowState, WorkflowStatus, WORKFLOW_STEPS, to_dict; print('OK')"</verify>
  <done>WorkflowState, WorkflowStatus, StepResult importable, to_dict/from_dict round-trip works</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `python -c "import ea_stress.core"` succeeds
- [ ] `python -c "from ea_stress.core.params import Parameter, OptimizationRange"` succeeds
- [ ] `python -c "from ea_stress.core.metrics import TradeMetrics, GateResult, calculate_composite_score"` succeeds
- [ ] `python -c "from ea_stress.core.state import WorkflowState, WorkflowStatus"` succeeds
- [ ] All dataclasses have type hints
- [ ] No dependencies on old code (engine/, modules/)
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- `ea_stress/core/` package created with 3 modules
- Domain models match Phase 1 specifications
- No modifications to existing code (engine/, modules/, reports/)
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-domain/02-01-SUMMARY.md`:

# Phase 02-core-domain Plan 01: Core Domain Models Summary

**[Substantive one-liner]**

## Accomplishments

- [Key outcome 1]
- [Key outcome 2]

## Files Created/Modified

- `ea_stress/__init__.py` - Package root
- `ea_stress/core/__init__.py` - Core subpackage
- `ea_stress/core/params.py` - Parameter and range models
- `ea_stress/core/metrics.py` - Trade metrics and scoring
- `ea_stress/core/state.py` - Workflow state model

## Decisions Made

[Key decisions and rationale, or "None"]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Phase Readiness

Phase 2 Plan 1 complete. Ready for Phase 3 (MT5 Abstraction).
</output>
