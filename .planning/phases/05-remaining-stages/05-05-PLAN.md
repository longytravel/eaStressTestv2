---
phase: 05-remaining-stages
plan: 05
type: execute
---

<objective>
Implement GenerateReportsStage (Step 11).

Purpose: Generate dashboard, leaderboard, and boards reports.
Output: `ea_stress/stages/s11_generate_reports.py`
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Prior summaries:
@.planning/phases/04-stage-framework/04-01-SUMMARY.md
@.planning/phases/05-remaining-stages/05-04-SUMMARY.md

# Specifications:
@.planning/phases/01-specification/specs/step-11-generate-reports.md

# Existing patterns:
@ea_stress/stages/base.py
@ea_stress/stages/s05_validate_trades.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement GenerateReportsStage class</name>
  <files>ea_stress/stages/s11_generate_reports.py</files>
  <action>
Create GenerateReportsStage following the Stage protocol.

This stage generates all report outputs:
1. Calculate final composite score from state metrics
2. Check go-live readiness (all critical gates passed)
3. Generate failure diagnosis if not ready
4. Generate three report types using existing reports module

Key from spec (step-11-generate-reports.md):
- Dashboard: Per-workflow interactive SPA
- Leaderboard: Global ranking across all workflows
- Boards: Workflow summary index

Critical gates for go-live:
- profit_factor, max_drawdown, minimum_trades, mc_confidence, mc_ruin

This stage ALWAYS runs, even when earlier steps fail.
Failed workflows still get dashboards showing what went wrong.

Gate: None (informational step).

Return StageResult with:
- dashboard_path: Path to generated dashboard
- leaderboard_path: Path to leaderboard
- boards_path: Path to boards
- composite_score: Final workflow score
- go_live_ready: Boolean
- diagnoses: List of failure explanations (if not ready)

Note: This stage delegates to existing reports module functions.
The stage wrapper provides clean Stage protocol interface.
  </action>
  <verify>python -c "from ea_stress.stages.s11_generate_reports import GenerateReportsStage; print(GenerateReportsStage().name)"</verify>
  <done>GenerateReportsStage class exists with name '11_generate_reports'</done>
</task>

<task type="auto">
  <name>Task 2: Export stage from package</name>
  <files>ea_stress/stages/__init__.py</files>
  <action>
Add GenerateReportsStage to lazy imports.

Update _stage_modules dict:
  "GenerateReportsStage": "s11_generate_reports"

Add to __all__ list.
  </action>
  <verify>python -c "from ea_stress.stages import GenerateReportsStage"</verify>
  <done>GenerateReportsStage importable from ea_stress.stages</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -c "from ea_stress.stages import GenerateReportsStage"` succeeds
- [ ] `python -m pytest -q` passes all existing tests
- [ ] GenerateReportsStage.name returns "11_generate_reports"
</verification>

<success_criteria>

- GenerateReportsStage wraps report generation functions
- Stage always succeeds (informational step)
- Stage calculates go-live readiness
- All existing tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/05-remaining-stages/05-05-SUMMARY.md`
</output>
